{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking Transformer-based NER "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter annotation files\n",
    "* create a copy of annotation files by excluding: \n",
    "        * keywords_to_remove = {\"Out-of-scope\",\"LSF_out_of_context\", \"Geographical_Feature\", \"Occupations\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files with keywords removed have been created in the output folder.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Input folder containing .ann files\n",
    "input_folder = '../../data/NER-Benchmarking/annotations/categorized/'\n",
    "# Output folder for modified files\n",
    "output_folder = '../../data/NER-Benchmarking/annotations/filtered/'\n",
    "\n",
    "# Keywords to remove\n",
    "keywords_to_remove = {\"Out-of-scope\",\"LSF_out_of_context\", \"Geographical_Feature\", \"Occupations\"}\n",
    "\n",
    "def remove_keywords(input_filepath, output_filepath):\n",
    "    with open(input_filepath, 'r') as input_file, open(output_filepath, 'w') as output_file:\n",
    "        for line in input_file:\n",
    "            line = line.strip()\n",
    "            if not any(keyword in line for keyword in keywords_to_remove):\n",
    "                output_file.write(line + '\\n')\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Iterate through .ann files in the input folder\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".ann\"):\n",
    "        input_filepath = os.path.join(input_folder, filename)\n",
    "        output_filepath = os.path.join(output_folder, filename)\n",
    "        remove_keywords(input_filepath, output_filepath)\n",
    "\n",
    "print(\"Files with keywords removed have been created in the output folder.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset\n",
    "* 20% hold out test data\n",
    "* 80% divided into 5 fold for cross validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split with considering the LSF types distribution between train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of Keywords in Test Set:\n",
      "  Mental_health_practices: 11 files\n",
      "  Non_physical_leisure_time_activities: 8 files\n",
      "  Beauty_and_Cleaning: 26 files\n",
      "  Drugs: 34 files\n",
      "  Environmental_exposures: 25 files\n",
      "  Socioeconomic_factors: 52 files\n",
      "  Physical_activity: 21 files\n",
      "  Nutrition: 66 files\n",
      "  Sleep: 20 files\n",
      "\n",
      "Distribution of Keywords in Train Set:\n",
      "  Mental_health_practices: 63 files\n",
      "  Non_physical_leisure_time_activities: 53 files\n",
      "  Beauty_and_Cleaning: 30 files\n",
      "  Drugs: 153 files\n",
      "  Environmental_exposures: 174 files\n",
      "  Socioeconomic_factors: 223 files\n",
      "  Physical_activity: 201 files\n",
      "  Nutrition: 379 files\n",
      "  Sleep: 90 files\n",
      "\n",
      "Number of Keywords in Test Set:\n",
      "Total: 263 files\n",
      "\n",
      "Number of Keywords in Train Set:\n",
      "Total: 1366 files\n",
      "Folding complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import random\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(1361)\n",
    "# Source directory containing your pairs of .txt and .ann files\n",
    "source_directory_txt = '../../data/NER-Benchmarking/annotations/raw/'\n",
    "source_directory_ann = '../../data/NER-Benchmarking/annotations/filtered/'\n",
    "\n",
    "# Root destination directory for folds and test data\n",
    "root_directory = '../../data/NER-Benchmarking/annotations/balanced_LSF_types_splits/'\n",
    "\n",
    "# Create the root directory if it doesn't exist\n",
    "os.makedirs(root_directory, exist_ok=True)\n",
    "\n",
    "# Create a directory for the test set\n",
    "test_directory = os.path.join(root_directory, 'test_data')\n",
    "os.makedirs(test_directory, exist_ok=True)\n",
    "\n",
    "# List all .txt files in the source directory\n",
    "txt_files = [filename for filename in os.listdir(source_directory_txt) if filename.endswith(\".txt\")]\n",
    "\n",
    "# Shuffle the list of .txt files randomly\n",
    "random.shuffle(txt_files)\n",
    "\n",
    "# Define the 9 keywords\n",
    "keywords = {\n",
    "    'Environmental_exposures',\n",
    "    'Physical_activity',\n",
    "    'Socioeconomic_factors',\n",
    "    'Drugs',\n",
    "    'Mental_health_practices',\n",
    "    'Non_physical_leisure_time_activities',\n",
    "    'Beauty_and_Cleaning',\n",
    "    'Nutrition',\n",
    "    'Sleep'\n",
    "}\n",
    "\n",
    "\n",
    "# List all .txt files in the source directory\n",
    "txt_files = [filename for filename in os.listdir(source_directory_txt) if filename.endswith(\".txt\")]\n",
    "\n",
    "# Shuffle the list of .txt files randomly while keeping the test size at 20%\n",
    "test_size = int(0.20 * len(txt_files))\n",
    "test_files = random.sample(txt_files, test_size)\n",
    "train_files = [file for file in txt_files if file not in test_files]\n",
    "\n",
    "\n",
    "\n",
    "# Create a dictionary to track keyword distribution in each fold\n",
    "keyword_counts = {keyword: [0] * 5 for keyword in keywords}\n",
    "\n",
    "# Calculate the distribution of keywords in the test set\n",
    "keyword_counts_test = {keyword: 0 for keyword in keywords}\n",
    "\n",
    "for txt_file in test_files:\n",
    "    ann_file = txt_file.replace(\".txt\", \".ann\")\n",
    "    source_ann_path = os.path.join(source_directory_ann, ann_file)\n",
    "\n",
    "    # Read the .ann file to identify the keywords\n",
    "    with open(source_ann_path, 'r') as ann_file_content:\n",
    "        for line in ann_file_content:\n",
    "            fields = line.strip().split()\n",
    "            if fields and fields[0].startswith('T'):\n",
    "                keyword = fields[1]  # Assumes the keyword appears as the second field\n",
    "                if keyword in keywords:\n",
    "                    keyword_counts_test[keyword] += 1\n",
    "\n",
    "# Calculate the distribution of keywords in the train set\n",
    "keyword_counts_train = {keyword: 0 for keyword in keywords}\n",
    "\n",
    "for txt_file in train_files:\n",
    "    ann_file = txt_file.replace(\".txt\", \".ann\")\n",
    "    source_ann_path = os.path.join(source_directory_ann, ann_file)\n",
    "\n",
    "    # Read the .ann file to identify the keywords\n",
    "    with open(source_ann_path, 'r') as ann_file_content:\n",
    "        for line in ann_file_content:\n",
    "            fields = line.strip().split()\n",
    "            if fields and fields[0].startswith('T'):\n",
    "                keyword = fields[1]  # Assumes the keyword appears as the second field\n",
    "                if keyword in keywords:\n",
    "                    keyword_counts_train[keyword] += 1\n",
    "\n",
    "# Check keyword distribution in test and train sets\n",
    "print(\"Distribution of Keywords in Test Set:\")\n",
    "for keyword, count in keyword_counts_test.items():\n",
    "    print(f\"  {keyword}: {count} files\")\n",
    "\n",
    "print(\"\\nDistribution of Keywords in Train Set:\")\n",
    "for keyword, count in keyword_counts_train.items():\n",
    "    print(f\"  {keyword}: {count} files\")\n",
    "\n",
    "# Copy test files to the test folder\n",
    "for txt_file in test_files:\n",
    "    ann_file = txt_file.replace(\".txt\", \".ann\")\n",
    "    dest_txt_path = os.path.join(test_directory, txt_file)\n",
    "    dest_ann_path = os.path.join(test_directory, ann_file)\n",
    "    shutil.copy(os.path.join(source_directory_txt, txt_file), dest_txt_path)\n",
    "    shutil.copy(os.path.join(source_directory_ann, ann_file), dest_ann_path)\n",
    "\n",
    "# Create directories for each fold in the train set\n",
    "num_folds = 5\n",
    "fold_size = len(train_files) // num_folds\n",
    "\n",
    "for fold in range(num_folds):\n",
    "    fold_directory = os.path.join(root_directory, f'fold_{fold + 1}')\n",
    "    os.makedirs(fold_directory, exist_ok=True)\n",
    "\n",
    "# Iterate over the .txt files in the train set and distribute them to folds\n",
    "for txt_file in train_files:\n",
    "    ann_file = txt_file.replace(\".txt\", \".ann\")\n",
    "    source_ann_path = os.path.join(source_directory_ann, ann_file)\n",
    "\n",
    "    fold_idx = txt_files.index(txt_file) % num_folds\n",
    "    fold_directory = os.path.join(root_directory, f'fold_{fold_idx + 1}')\n",
    "    dest_txt_path = os.path.join(fold_directory, txt_file)\n",
    "    dest_ann_path = os.path.join(fold_directory, ann_file)\n",
    "\n",
    "    shutil.copy(os.path.join(source_directory_txt, txt_file), dest_txt_path)\n",
    "    shutil.copy(source_ann_path, dest_ann_path)\n",
    "\n",
    "\n",
    "print(\"\\nNumber of Keywords in Test Set:\")\n",
    "total_keywords_test = sum(keyword_counts_test.values())\n",
    "\n",
    "print(f\"Total: {total_keywords_test} files\")\n",
    "\n",
    "print(\"\\nNumber of Keywords in Train Set:\")\n",
    "total_keywords_train = sum(keyword_counts_train.values())\n",
    "print(f\"Total: {total_keywords_train} files\")\n",
    "\n",
    "print(\"Folding complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to CONLL format\n",
    "* Note: this can be done even before spliiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "def convert_to_CONLL(root_folder, script_path, output_suffix, singletype=None):\n",
    "    for subdir in os.listdir(root_folder):\n",
    "        subdir_path = os.path.join(root_folder, subdir)\n",
    "        if os.path.isdir(subdir_path):\n",
    "            output_file = os.path.join(root_folder, f'{subdir}_{output_suffix}.tsv')\n",
    "            if singletype:\n",
    "                command = f\"python  {script_path}  -1 {singletype} {subdir_path} > {output_file}\"\n",
    "                subprocess.call(command, shell=True)\n",
    "            else:\n",
    "                command = f\"python  {script_path}  {subdir_path} > {output_file}\"\n",
    "                subprocess.call(command, shell=True)\n",
    "\n",
    "# Example usage:\n",
    "root_folder = '../../data/NER-Benchmarking/annotations/balanced_LSF_types_splits/'\n",
    "\n",
    "script_path = '../../standoff2conll/standoff2conll.py'\n",
    "output_suffix = 'merged_only_LSF'  # Customize the output file suffix\n",
    "\n",
    "# Call the function with -1 LSF in arguments\n",
    "singletype = 'LSF'  # Replace with the desired singletype\n",
    "convert_to_CONLL(root_folder, script_path, output_suffix, singletype)\n",
    "\n",
    "# Call the function without -1 LSF in arguments\n",
    "# removed -1 LSF to explicitly mention LSF branch instead of single LSF type\n",
    "output_suffix='merged_with_LSF_branches'\n",
    "convert_to_CONLL(root_folder, script_path, output_suffix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to Transformer-NER folder\n",
    "! cp ../../data/NER-Benchmarking/annotations/balanced_LSF_types_splits/test_data_merged_only_LSF.tsv  ../../S1000_Transformer_NER/data/\n",
    "! cp ../../data/NER-Benchmarking/annotations/balanced_LSF_types_splits/test_data_merged_with_LSF_branches.tsv  ../../S1000_Transformer_NER/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge folds to create single train file\n",
    "* to be used after grid search for training the final model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def concatenate_files(file_names, output_file):\n",
    "    # Initialize an empty DataFrame to store the concatenated data\n",
    "    concatenated_df = pd.DataFrame()\n",
    "\n",
    "    # Loop through each file and concatenate its contents to the DataFrame\n",
    "    for file_name in file_names:\n",
    "        # Assuming that the first row contains column headers\n",
    "        df = pd.read_csv(file_name, sep='\\t', header=None)\n",
    "        concatenated_df = pd.concat([concatenated_df, df], ignore_index=True)\n",
    "\n",
    "    # Save the concatenated DataFrame to a new TSV file\n",
    "    concatenated_df.to_csv(output_file, sep='\\t', index=False, header=None)\n",
    "\n",
    "\n",
    "\n",
    "# List of file names to concatenate\n",
    "file_names = ['../../data/NER-Benchmarking/annotations/balanced_LSF_types_splits/fold_1_merged_only_LSF.tsv',\n",
    "              '../../data/NER-Benchmarking/annotations/balanced_LSF_types_splits/fold_2_merged_only_LSF.tsv',\n",
    "              '../../data/NER-Benchmarking/annotations/balanced_LSF_types_splits/fold_3_merged_only_LSF.tsv',\n",
    "              '../../data/NER-Benchmarking/annotations/balanced_LSF_types_splits/fold_4_merged_only_LSF.tsv',\n",
    "              '../../data/NER-Benchmarking/annotations/balanced_LSF_types_splits/fold_5_merged_only_LSF.tsv']\n",
    "              \n",
    "\n",
    "# Output file name\n",
    "output_file = '../../S1000_Transformer_NER/data/train_data_merged_only_LSF.tsv'\n",
    "\n",
    "# Call the function to concatenate files\n",
    "concatenate_files(file_names, output_file)\n",
    "\n",
    "\n",
    "\n",
    "# List of file names to concatenate\n",
    "file_names = ['../../data/NER-Benchmarking/annotations/balanced_LSF_types_splits/fold_1_merged_with_LSF_branches.tsv',\n",
    "              '../../data/NER-Benchmarking/annotations/balanced_LSF_types_splits/fold_2_merged_with_LSF_branches.tsv',\n",
    "              '../../data/NER-Benchmarking/annotations/balanced_LSF_types_splits/fold_3_merged_with_LSF_branches.tsv',\n",
    "              '../../data/NER-Benchmarking/annotations/balanced_LSF_types_splits/fold_4_merged_with_LSF_branches.tsv',\n",
    "              '../../data/NER-Benchmarking/annotations/balanced_LSF_types_splits/fold_5_merged_with_LSF_branches.tsv']\n",
    "\n",
    "# Output file name\n",
    "output_file = '../../S1000_Transformer_NER/data/train_data_merged_with_LSF_branches.tsv'\n",
    "\n",
    "# Call the function to concatenate files\n",
    "concatenate_files(file_names, output_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create single tsv test file from txt files\n",
    "* there will be 6 tab separated columns, first is the abstract id and last is the contnt, other are just be compatible with requested format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSV file '../../S1000_Transformer_NER/data/test_data_merged_Tagger_format.tsv' created successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def create_single_tsv_from_txt_files(input_dir, output_tsv_file):\n",
    "    # Filler dummy words for the middle columns\n",
    "    dummy_words = [\"other_ids\", \"authors\", \"forum\", \"year\"]\n",
    "\n",
    "    # Initialize an empty list to store the TSV lines\n",
    "    tsv_lines = []\n",
    "\n",
    "    # Loop through the TXT files in the input directory\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            # Read the content of the TXT file without modifications\n",
    "            with open(os.path.join(input_dir, filename), 'r') as txt_file:\n",
    "                file_content = txt_file.read().strip()\n",
    "\n",
    "                # Remove newline characters from the file content\n",
    "                #file_content = file_content.replace('\\n', ' ').replace('\\r', '')\n",
    "                file_content = file_content.replace('\\n', '')\n",
    "\n",
    "            # Create a TSV line for the current file\n",
    "            tsv_line = [filename] + dummy_words + ['\"' + file_content + '\"']\n",
    "            tsv_lines.append(\"\\t\".join(tsv_line))\n",
    "\n",
    "    # Write the TSV lines to the output file\n",
    "    with open(output_tsv_file, 'w') as output_file:\n",
    "        output_file.write(\"\\n\".join(tsv_lines))\n",
    "\n",
    "    print(f\"TSV file '{output_tsv_file}' created successfully.\")\n",
    "\n",
    "input_dir = '../../data/NER-Benchmarking/annotations/balanced_LSF_types_splits/test_data/'\n",
    "output_tsv_file = '../../S1000_Transformer_NER/data/test_data_merged_Tagger_format.tsv'\n",
    "create_single_tsv_from_txt_files(input_dir, output_tsv_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Grid Search "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To find best hyperparameters we use the second approach from the following options:\n",
    "\n",
    "    *  In cross-validation, calculating precision and recall by summing TP (True Positives), FP (False Positives), and FN (False Negatives) across all folds can yield different results compared to averaging precision and recall across folds. Here's how they differ:\n",
    "\n",
    "1. Averaging Precision and Recall Across Folds:\n",
    "   - For each fold, you calculate precision and recall separately.\n",
    "   - Then, you average the precision and recall values obtained from all folds.\n",
    "   - This method gives equal weight to each fold, ensuring that the contribution of each fold to the final result is the same.\n",
    "\n",
    "2. Summing TP, FP, and FN Across All Folds:\n",
    "   - In this approach, you sum TP, FP, and FN across all folds to calculate the overall values for the entire dataset.\n",
    "   - Afterward, you calculate precision and recall based on these summed values.\n",
    "   - This method treats the entire dataset as a single unit and computes precision and recall as if it were a single large dataset.\n",
    "\n",
    "   Here's how you can calculate precision and recall in the summing approach for each fold:\n",
    "\n",
    "    Sum TP, FP, and FN across all folds:\n",
    "        Calculate the total TP, FP, and FN across all folds by summing the corresponding counts from each fold.\n",
    "\n",
    "    Calculate Precision and Recall:\n",
    "\n",
    "        Once you have the total TP, FP, and FN counts, you can calculate precision and recall as follows:\n",
    "\n",
    "        Precision = Total TP / (Total TP + Total FP)\n",
    "\n",
    "        Recall = Total TP / (Total TP + Total FN)\n",
    "\n",
    "The key difference lies in how they handle the division of the dataset. Here are some considerations for each approach:\n",
    "\n",
    "- Averaging precision and recall across folds is useful when you want to evaluate the model's performance on each fold independently and then obtain an average performance metric. It provides insights into how well the model generalizes across different subsets of the data.\n",
    "\n",
    "- Summing TP, FP, and FN across all folds treats the entire dataset as a whole, which can be beneficial when you want an overall assessment of the model's performance across the entire dataset. However, it may not provide information about how consistent the model's performance is across different subsets of data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train with final hyperparametrs from grid search\n",
    "* Data:\n",
    "    * merge all 5 folds to create a merged file \n",
    "        * train file: '../../S1000_Transformer_NER/data/train_data_with_LSF_branches.tsv'\n",
    "        * test data: '../../S1000_Transformer_NER/data/test_data_merged_with_LSF_branches.tsv'\n",
    "\n",
    "* Hyperparametrs:\n",
    "    * Best set from Grid Search\n",
    "    * epoch:60, lr:1e-5, batch:16, seq:256\n",
    "\n",
    "* Models:\n",
    "    * RoBERTa large path:\n",
    "        * running ./setup.sh in root path of S1000-transformer-ner repo downloads RoBERTa-large model in the root directory\n",
    "\n",
    "\n",
    "* Run script:\n",
    "    * update run-ner.sh for hyperparametrs and paths\n",
    "    * run '../../S1000_Transformer_NER/scripts/run-ner.sh'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Output files:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1. NER output whcih shows what entities are detected in test set in the BIO format\n",
    "    * '../../S1000_Transformer_NER/output/test_with_LSF_branches.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2. Performance results along with TP,FP,FN counts\n",
    "    * '../../S1000_Transformer_NER/results/results_test_with_LSF_branches.csv'\n",
    "    * results.columns=['experiment_ID','max_seq_length','model_name','num_train_epochs','learning_rate','batch_size','predict_position','train_data','test_data','method','prec','rec','F','TP','FP','FN']\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get predictions using S1000 Transformer Tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note: Trained Transformer NER can be evaulated in 2 different ways:\n",
    "    * 1. Evaluation script which is available in the repo of NER and by default is calculated (the approach used to do grid search)\n",
    "    * 2. There is Transformer Taggger that uses the fine tuned model in the first step to tag or detect entities in the text\n",
    "            * This approach recieves the input in a string db format (6 columns tsv file where each row is an abstract and first column is pmid abd the last column is the asbtract text)\n",
    "            * This creates predictions in tagger format which is a tsv file for mentions and their offset in abstract and etc. \n",
    "            * This file can be converted to corresponding *.ann files similar to what we did for tagger macthes and then we can compare manual annotations with predicted *.ann similar to what we did for benchmarking\n",
    "            * This approach produces improved results because we use -o argument which considers overlaping matches as match, without this arguument the result will be decreased significantly(similar can happen to tagger results) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Prepare files\n",
    "* Modify script to point the required input files and trained model in the previous step:\n",
    "    * '../S1000_Transformer_Tagger/scripts/run-bio-tagger.sh'\n",
    "        1. Input files:\n",
    "            * Test data file:\n",
    "                * '../S1000_Transformer_NER/data/test_data_Tagger_format.tsv' \n",
    "        \n",
    "        2. Trained Model:\n",
    "            * '../S1000_Transformer_NER/ner-models/s1000'\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Run script\n",
    "* cd S1000-transformer-tagger/\n",
    "    * ./scripts/run-bio-tagger.sh\n",
    "        * this will create ouputs in \n",
    "            * S1000-transformer-tagger/output/output-spans.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Convert predictions to *.ann files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def create_ann_files_from_NER_output(input_file, output_ann_folder):\n",
    "    # Read the input file, remove duplicates, and write to the output file\n",
    "    df = pd.read_csv(input_file, sep='\\t', header=None)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.to_csv(input_file, index=False, header=None, sep='\\t')\n",
    "\n",
    "    os.makedirs(output_ann_folder, exist_ok=True)\n",
    "\n",
    "    previous_value = None\n",
    "    counter = 1\n",
    "\n",
    "    with open(input_file, 'r', encoding='utf-8-sig') as input_file:\n",
    "        for line in input_file:\n",
    "            fields = line.strip().split('\\t')\n",
    "            current_value = fields[0]\n",
    "            # Remove .txt extension from filename\n",
    "            current_value = current_value.rstrip()[:-4]\n",
    "\n",
    "            if current_value != previous_value:\n",
    "                counter = 1  # Reset the counter for a new value in the first column\n",
    "                previous_value = current_value\n",
    "\n",
    "            filename = os.path.join(output_ann_folder, current_value + '.ann')\n",
    "            with open(filename, 'a', encoding='utf-8') as output_file:\n",
    "                span_text = f'{fields[6]} {int(fields[3])-1} {int(fields[4])}'\n",
    "                span_text = span_text.replace('\\xa0', ' ')  # Replace non-breaking space with a normal space\n",
    "                output_file.write(f'T{counter}\\t{span_text}\\t{fields[5]}\\n')\n",
    "\n",
    "            counter += 1\n",
    "\n",
    "\n",
    "input_file = '../../S1000_Transformer_Tagger/output/output-spans.tsv'\n",
    "output_ann_folder = '../../S1000_Transformer_Tagger/output/transformer_predicted_ann_files/'\n",
    "create_ann_files_from_NER_output(input_file, output_ann_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Create empty ann files for those abstracts that don't have them because NER has not found any matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "\n",
    "def create_missing_ann_files(ann_dir,txt_dir):\n",
    "    for filename in os.listdir(txt_dir):\n",
    "        if filename.endswith('.txt'):\n",
    "            txt_file_path = os.path.join(ann_dir, filename)\n",
    "            ann_file_path = os.path.splitext(txt_file_path)[0] + '.ann'\n",
    "            \n",
    "            if not os.path.exists(ann_file_path):\n",
    "                with open(ann_file_path, 'w') as ann_file:\n",
    "                    pass  # Creates an empty .ann file\n",
    "\n",
    "ann_dir = '../../S1000_Transformer_Tagger/output/transformer_predicted_ann_files/'\n",
    "txt_dir ='../../data/NER-Benchmarking/annotations/balanced_LSF_types_splits/test_data/'\n",
    "\n",
    "create_missing_ann_files(ann_dir,txt_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.calculate performance in comparison with manual annotations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with different LSF branches \n",
    "!python2 ../../utils/IAA.py -o -d -v     '../../data/NER-Benchmarking/annotations/balanced_LSF_types_splits/test_data/'    '../../S1000_Transformer_Tagger/output/transformer_predicted_ann_files/'  --allowmissing > ../../S1000_Transformer_NER/results/Transformer_Tagger_Performance_test_data_with_LSF_types.txt 2>&1\n",
    "\n",
    "#using -i to ignore different LSF branches and consider single LSF enity type\n",
    "!python2 ../../utils/IAA.py -o -d -v  -i  '../../data/NER-Benchmarking/annotations/balanced_LSF_types_splits/test_data/'    '../../S1000_Transformer_Tagger/output/transformer_predicted_ann_files/'  --allowmissing > ../../S1000_Transformer_NER/results/Transformer_Tagger_Performance_test_data_single_LSF_type.stv 2>&1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.produce tagger matches using dictionary based-NER-matches for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python2 ../../../utils/IAA.py -o -d -v   '../../data/s1000_ner/balanced_LSF_types_splits/test_data/'   \"../../data/200_abstracts/taggers_matches/brat_files/\" --allowmissing > ../../data/s1000_ner/results/performance_Tagger_for_Test_Data.txt 2>&1\n",
    "!python2 ../../utils/IAA.py -o -d -v   '../../data/NER-Benchmarking/annotations/balanced_LSF_types_splits/test_data/'   '../../data/NER-Benchmarking/tagger/tagger_output/brat_files/'  >../../S1000_Transformer_NER/results/Dictionary_based_Tagger_Performance_test_data_with_LSF_types.txt 2>&1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* extract metrics from text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_data_and_save(file_path):\n",
    "    # Initialize an empty DataFrame\n",
    "    pr_rec_per_lsf_branch = pd.DataFrame(columns=['Lifestyle-factor branch', 'Precision', 'Recall', 'F'])\n",
    "\n",
    "    # Read the text from the file\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Split the text into lines\n",
    "    lines = text.strip().split('\\n')\n",
    "\n",
    "    # Iterate over each line and extract data\n",
    "    for line in lines:\n",
    "        match = re.match(r'TYPE:\\s+(.*?)\\s+precision\\s+([\\d.]+%)\\s+\\((\\d+)/(\\d+)\\)\\s+recall\\s+([\\d.]+%)\\s+\\((\\d+)/(\\d+)\\)\\s+F\\s+([\\d.]+)', line)\n",
    "        if match:\n",
    "            revision_step, precision, _, _, recall, _, _, f_score = match.groups()\n",
    "            if revision_step not in ['Beauty_and_Cleaning', 'Drugs', 'Environmental_exposures',\n",
    "                                     'Mental_health_practices', 'Non_physical_leisure_time_activities',\n",
    "                                     'Nutrition', 'Physical_activity', 'Sleep', 'Socioeconomic_factors']:\n",
    "                continue\n",
    "\n",
    "            # Remove the percentage symbols and convert to floats\n",
    "            precision = float(precision.rstrip('%'))\n",
    "            recall = float(recall.rstrip('%'))\n",
    "            f_score = float(f_score)\n",
    "            # Append the data to the DataFrame\n",
    "            pr_rec_per_lsf_branch = pr_rec_per_lsf_branch.append({\n",
    "                'Lifestyle-factor branch': revision_step.strip(),\n",
    "                'Precision': precision,\n",
    "                'Recall': recall,\n",
    "                'F': f_score\n",
    "            }, ignore_index=True)\n",
    "\n",
    "    # Sort the DataFrame by the 'F' column in ascending order\n",
    "    pr_rec_per_lsf_branch = pr_rec_per_lsf_branch.sort_values(by='F')\n",
    "    \n",
    "    # Return the resulting DataFrame\n",
    "    return pr_rec_per_lsf_branch\n",
    "\n",
    "# full_output Dictionary based NER for test data:\n",
    "file_path = '../../S1000_Transformer_NER/results/Dictionary_based_Tagger_Performance_test_data_with_LSF_types.txt'\n",
    "\n",
    "resulting_df = extract_data_and_save(file_path)\n",
    "# Save the DataFrame to a TSV file\n",
    "Dict_based_NER_file_path = '../../S1000_Transformer_NER/results/Dictionary_based_Tagger_Performance_test_data_with_LSF_types_prec_rec.tsv'\n",
    "resulting_df.to_csv(Dict_based_NER_file_path, sep='\\t', index=None)\n",
    "\n",
    "\n",
    "\n",
    "# full_output S1000 NER for test data:\n",
    "file_path = '../../S1000_Transformer_NER/results/Transformer_Tagger_Performance_test_data_with_LSF_types.txt'\n",
    "resulting_df = extract_data_and_save(file_path)\n",
    "# Save the DataFrame to a TSV file\n",
    "Transformer_based_NER_file_path = '../../S1000_Transformer_NER/results/Transformer_Tagger_Performance_test_data_with_LSF_types_prec_rec.tsv'\n",
    "resulting_df.to_csv(Transformer_based_NER_file_path, sep='\\t', index=None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Modify lables to be appropriate for plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "def replace_phrases_in_dataframe(input_file_path, phrase_replacements):\n",
    "    # Read the input TSV file into a DataFrame\n",
    "    df = pd.read_csv(input_file_path, sep='\\t')\n",
    "\n",
    "    # Replace the phrases in the DataFrame\n",
    "    df['Lifestyle-factor branch'] = df['Lifestyle-factor branch'].replace(phrase_replacements)\n",
    "\n",
    "    # Write the modified DataFrame to the output TSV file\n",
    "    df.to_csv(input_file_path, sep='\\t', index=False)\n",
    "\n",
    "\n",
    "phrase_replacements = {\n",
    "    'Environmental_exposures': 'Environmental exposures',\n",
    "    'Physical_activity': 'Physical activities',\n",
    "    'Socioeconomic_factors': 'Socioeconomic factors',\n",
    "    'Drugs': 'Substance use',\n",
    "    'Mental_health_practices': 'Mental health practices',\n",
    "    'Non_physical_leisure_time_activities': 'Non physical leisure time activities',\n",
    "    'Beauty_and_Cleaning': 'Beauty and cleaning'\n",
    "}\n",
    "\n",
    "\n",
    "# replace names in both files\n",
    "replace_phrases_in_dataframe(Dict_based_NER_file_path, phrase_replacements)\n",
    "\n",
    "replace_phrases_in_dataframe(Transformer_based_NER_file_path, phrase_replacements)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# merge two files\n",
    "\n",
    "df_tagger = pd.read_csv(Dict_based_NER_file_path, sep='\\t')\n",
    "df2_transformer = pd.read_csv(Transformer_based_NER_file_path, sep='\\t')\n",
    "df2_transformer.columns = ['Lifestyle-factor branch']+[col + '_transformer' for col in df2_transformer.columns if col!='Lifestyle-factor branch']\n",
    "\n",
    "merged_df = df_tagger.merge(df2_transformer, on='Lifestyle-factor branch')\n",
    "\n",
    "# Save the merged DataFrame to a new TSV file\n",
    "merged_file ='../../S1000_Transformer_NER/results/plot_input_compare_DIC_VS_Transformer.tsv'\n",
    "\n",
    "#merged_df=merged_df.sort_values(by=['Lifestyle-factor branch'])\n",
    "\n",
    "desired_order = ['nutrition', 'socioeconomic factors', 'environmental exposures', 'substance use','physical activities', 'beauty and cleaning',  'non physical leisure time activities',  'sleep' , 'mental health practices']\n",
    "# Create a new column with the order of 'Lifestyle-factor branch' (ignoring case)\n",
    "merged_df['Order'] = merged_df['Lifestyle-factor branch'].str.lower().map({value.lower(): index for index, value in enumerate(desired_order)})\n",
    "# Sort the DataFrame based on the new 'Order' column\n",
    "merged_df_sorted = merged_df.sort_values(by='Order').drop('Order', axis=1)\n",
    "merged_df_sorted.to_csv(merged_file, sep='\\t', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* plot by comparing Tagger Ner with Transformer NER\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dzq660/miniforge3/envs/lsf/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "Figure(1200x1200)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#!python3 ../plot_prec_rec_Deep_vs_Tagger.py --input_file=../../data/s1000_ner/results/plot_input_compare_DIC_VS_Transformer.tsv --task=\"Performance of Transformer-based and Dictonary-based NER (Test-Data)\" --output_file=../../data/s1000_ner/results/plot_Tagger_VS_Transformer_NER.png\n",
    "!python3 ../NER-Benchmarking/scripts/plot_prec_rec_Deep_vs_Tagger.py  --input_file=../../S1000_Transformer_NER/results/plot_input_compare_DIC_VS_Transformer.tsv --task=\"\" --output_file=../../plots/plot_Tagger_VS_Transformer_NER.png\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lsf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
